{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from trainer import Trainer\n",
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gets the parameters from the config.json file \n",
    "def get_instance(module, name, config, *args):\n",
    "    return getattr(module, config[name]['type'])(*args, **config[name]['args'])\n",
    "\n",
    "def main(config, resume):\n",
    "    train_logger = Logger() #uses entries to store training performance metrics\n",
    "\n",
    "    # setup data_loader instances\n",
    "    data_loader = get_instance(module_data, 'data_loader', config) #looks in data_loader/data_loaders.py for 'MNISTDataLoader'\n",
    "    valid_data_loader = data_loader.split_validation() #allocate some images as validation\n",
    "\n",
    "    # build model architecture\n",
    "    model = get_instance(module_arch, 'arch', config) #looks in the model/model.py for 'MnistModel', as specified by config\n",
    "    print(model)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "    # get function handles of loss and metrics\n",
    "    loss = getattr(module_loss, config['loss']) #looks in model/loss.py for 'nll_loss'\n",
    "    metrics = [getattr(module_metric, met) for met in config['metrics']] #get all the metrics in model/metrics.py - default is accuracy and top 3 accuracy\n",
    "\n",
    "    # build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters()) #Number of training params\n",
    "    optimizer = get_instance(torch.optim, 'optimizer', config, trainable_params)\n",
    "    lr_scheduler = get_instance(torch.optim.lr_scheduler, 'lr_scheduler', config, optimizer)\n",
    "\n",
    "    trainer = Trainer(model, loss, metrics, optimizer,\n",
    "                      resume=resume, #choose a previous epoch to start training from\n",
    "                      config=config,\n",
    "                      data_loader=data_loader,\n",
    "                      valid_data_loader=valid_data_loader,\n",
    "                      lr_scheduler=lr_scheduler,\n",
    "                      train_logger=train_logger)\n",
    "\n",
    "    trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config.json'\n",
    "# load config file\n",
    "with open(config_file) as handle:\n",
    "    config = json.load(handle)\n",
    "# setting path to save trained models and log files\n",
    "path = os.path.join(config['trainer']['save_dir'], config['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Trainable parameters: 21840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 2.308060\n",
      "Train Epoch: 1 [1408/54000 (3%)] Loss: 2.230936\n",
      "Train Epoch: 1 [2816/54000 (5%)] Loss: 2.034446\n",
      "Train Epoch: 1 [4224/54000 (8%)] Loss: 1.682630\n",
      "Train Epoch: 1 [5632/54000 (10%)] Loss: 1.279940\n",
      "Train Epoch: 1 [7040/54000 (13%)] Loss: 1.150876\n",
      "Train Epoch: 1 [8448/54000 (16%)] Loss: 0.933038\n",
      "Train Epoch: 1 [9856/54000 (18%)] Loss: 0.658498\n",
      "Train Epoch: 1 [11264/54000 (21%)] Loss: 0.630270\n",
      "Train Epoch: 1 [12672/54000 (23%)] Loss: 0.689489\n",
      "Train Epoch: 1 [14080/54000 (26%)] Loss: 0.701856\n",
      "Train Epoch: 1 [15488/54000 (29%)] Loss: 0.636871\n",
      "Train Epoch: 1 [16896/54000 (31%)] Loss: 0.671162\n",
      "Train Epoch: 1 [18304/54000 (34%)] Loss: 0.748563\n",
      "Train Epoch: 1 [19712/54000 (36%)] Loss: 0.578480\n",
      "Train Epoch: 1 [21120/54000 (39%)] Loss: 0.631065\n",
      "Train Epoch: 1 [22528/54000 (42%)] Loss: 0.490486\n",
      "Train Epoch: 1 [23936/54000 (44%)] Loss: 0.392174\n",
      "Train Epoch: 1 [25344/54000 (47%)] Loss: 0.374846\n",
      "Train Epoch: 1 [26752/54000 (50%)] Loss: 0.369213\n",
      "Train Epoch: 1 [28160/54000 (52%)] Loss: 0.424163\n",
      "Train Epoch: 1 [29568/54000 (55%)] Loss: 0.305041\n",
      "Train Epoch: 1 [30976/54000 (57%)] Loss: 0.558736\n",
      "Train Epoch: 1 [32384/54000 (60%)] Loss: 0.530849\n",
      "Train Epoch: 1 [33792/54000 (63%)] Loss: 0.414943\n",
      "Train Epoch: 1 [35200/54000 (65%)] Loss: 0.484344\n",
      "Train Epoch: 1 [36608/54000 (68%)] Loss: 0.509143\n",
      "Train Epoch: 1 [38016/54000 (70%)] Loss: 0.546407\n",
      "Train Epoch: 1 [39424/54000 (73%)] Loss: 0.361439\n",
      "Train Epoch: 1 [40832/54000 (76%)] Loss: 0.358978\n",
      "Train Epoch: 1 [42240/54000 (78%)] Loss: 0.350124\n",
      "Train Epoch: 1 [43648/54000 (81%)] Loss: 0.333507\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: 0.409494\n",
      "Train Epoch: 1 [46464/54000 (86%)] Loss: 0.395986\n",
      "Train Epoch: 1 [47872/54000 (89%)] Loss: 0.573001\n",
      "Train Epoch: 1 [49280/54000 (91%)] Loss: 0.350502\n",
      "Train Epoch: 1 [50688/54000 (94%)] Loss: 0.305845\n",
      "Train Epoch: 1 [52096/54000 (96%)] Loss: 0.368564\n",
      "Train Epoch: 1 [53504/54000 (99%)] Loss: 0.215205\n",
      "    val_my_metric2 : 0.9956781914893617\n",
      "    my_metric2     : 0.9245144295870007\n",
      "    my_metric      : 0.7880337042992552\n",
      "    val_loss       : 0.12521308284015098\n",
      "    val_my_metric  : 0.964356952887538\n",
      "    loss           : 0.6688278279668912\n",
      "    epoch          : 1\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch1.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: 0.334085\n",
      "Train Epoch: 2 [1408/54000 (3%)] Loss: 0.416333\n",
      "Train Epoch: 2 [2816/54000 (5%)] Loss: 0.254802\n",
      "Train Epoch: 2 [4224/54000 (8%)] Loss: 0.224608\n",
      "Train Epoch: 2 [5632/54000 (10%)] Loss: 0.429526\n",
      "Train Epoch: 2 [7040/54000 (13%)] Loss: 0.342926\n",
      "Train Epoch: 2 [8448/54000 (16%)] Loss: 0.351208\n",
      "Train Epoch: 2 [9856/54000 (18%)] Loss: 0.279029\n",
      "Train Epoch: 2 [11264/54000 (21%)] Loss: 0.594411\n",
      "Train Epoch: 2 [12672/54000 (23%)] Loss: 0.395971\n",
      "Train Epoch: 2 [14080/54000 (26%)] Loss: 0.209269\n",
      "Train Epoch: 2 [15488/54000 (29%)] Loss: 0.187988\n",
      "Train Epoch: 2 [16896/54000 (31%)] Loss: 0.265236\n",
      "Train Epoch: 2 [18304/54000 (34%)] Loss: 0.342734\n",
      "Train Epoch: 2 [19712/54000 (36%)] Loss: 0.235257\n",
      "Train Epoch: 2 [21120/54000 (39%)] Loss: 0.335193\n",
      "Train Epoch: 2 [22528/54000 (42%)] Loss: 0.342796\n",
      "Train Epoch: 2 [23936/54000 (44%)] Loss: 0.298216\n",
      "Train Epoch: 2 [25344/54000 (47%)] Loss: 0.351809\n",
      "Train Epoch: 2 [26752/54000 (50%)] Loss: 0.290278\n",
      "Train Epoch: 2 [28160/54000 (52%)] Loss: 0.238445\n",
      "Train Epoch: 2 [29568/54000 (55%)] Loss: 0.251343\n",
      "Train Epoch: 2 [30976/54000 (57%)] Loss: 0.303190\n",
      "Train Epoch: 2 [32384/54000 (60%)] Loss: 0.472629\n",
      "Train Epoch: 2 [33792/54000 (63%)] Loss: 0.200712\n",
      "Train Epoch: 2 [35200/54000 (65%)] Loss: 0.224139\n",
      "Train Epoch: 2 [36608/54000 (68%)] Loss: 0.175673\n",
      "Train Epoch: 2 [38016/54000 (70%)] Loss: 0.334655\n",
      "Train Epoch: 2 [39424/54000 (73%)] Loss: 0.268397\n",
      "Train Epoch: 2 [40832/54000 (76%)] Loss: 0.176681\n",
      "Train Epoch: 2 [42240/54000 (78%)] Loss: 0.199770\n",
      "Train Epoch: 2 [43648/54000 (81%)] Loss: 0.366841\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: 0.234069\n",
      "Train Epoch: 2 [46464/54000 (86%)] Loss: 0.320072\n",
      "Train Epoch: 2 [47872/54000 (89%)] Loss: 0.292901\n",
      "Train Epoch: 2 [49280/54000 (91%)] Loss: 0.236674\n",
      "Train Epoch: 2 [50688/54000 (94%)] Loss: 0.290127\n",
      "Train Epoch: 2 [52096/54000 (96%)] Loss: 0.206465\n",
      "Train Epoch: 2 [53504/54000 (99%)] Loss: 0.200399\n",
      "    val_my_metric2 : 0.9978390957446809\n",
      "    my_metric2     : 0.9849251015572105\n",
      "    my_metric      : 0.9131500719363574\n",
      "    val_loss       : 0.08763692595381686\n",
      "    val_my_metric  : 0.9728106003039514\n",
      "    loss           : 0.2981309673585598\n",
      "    epoch          : 2\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch2.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: 0.252151\n",
      "Train Epoch: 3 [1408/54000 (3%)] Loss: 0.220168\n",
      "Train Epoch: 3 [2816/54000 (5%)] Loss: 0.406511\n",
      "Train Epoch: 3 [4224/54000 (8%)] Loss: 0.181340\n",
      "Train Epoch: 3 [5632/54000 (10%)] Loss: 0.129242\n",
      "Train Epoch: 3 [7040/54000 (13%)] Loss: 0.157013\n",
      "Train Epoch: 3 [8448/54000 (16%)] Loss: 0.235692\n",
      "Train Epoch: 3 [9856/54000 (18%)] Loss: 0.379805\n",
      "Train Epoch: 3 [11264/54000 (21%)] Loss: 0.242758\n",
      "Train Epoch: 3 [12672/54000 (23%)] Loss: 0.241151\n",
      "Train Epoch: 3 [14080/54000 (26%)] Loss: 0.272714\n",
      "Train Epoch: 3 [15488/54000 (29%)] Loss: 0.194557\n",
      "Train Epoch: 3 [16896/54000 (31%)] Loss: 0.172609\n",
      "Train Epoch: 3 [18304/54000 (34%)] Loss: 0.250733\n",
      "Train Epoch: 3 [19712/54000 (36%)] Loss: 0.282080\n",
      "Train Epoch: 3 [21120/54000 (39%)] Loss: 0.339860\n",
      "Train Epoch: 3 [22528/54000 (42%)] Loss: 0.351886\n",
      "Train Epoch: 3 [23936/54000 (44%)] Loss: 0.292116\n",
      "Train Epoch: 3 [25344/54000 (47%)] Loss: 0.178125\n",
      "Train Epoch: 3 [26752/54000 (50%)] Loss: 0.471956\n",
      "Train Epoch: 3 [28160/54000 (52%)] Loss: 0.444255\n",
      "Train Epoch: 3 [29568/54000 (55%)] Loss: 0.246158\n",
      "Train Epoch: 3 [30976/54000 (57%)] Loss: 0.221577\n",
      "Train Epoch: 3 [32384/54000 (60%)] Loss: 0.154621\n",
      "Train Epoch: 3 [33792/54000 (63%)] Loss: 0.155003\n",
      "Train Epoch: 3 [35200/54000 (65%)] Loss: 0.230116\n",
      "Train Epoch: 3 [36608/54000 (68%)] Loss: 0.197510\n",
      "Train Epoch: 3 [38016/54000 (70%)] Loss: 0.227792\n",
      "Train Epoch: 3 [39424/54000 (73%)] Loss: 0.199637\n",
      "Train Epoch: 3 [40832/54000 (76%)] Loss: 0.152441\n",
      "Train Epoch: 3 [42240/54000 (78%)] Loss: 0.364867\n",
      "Train Epoch: 3 [43648/54000 (81%)] Loss: 0.217872\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: 0.253627\n",
      "Train Epoch: 3 [46464/54000 (86%)] Loss: 0.302586\n",
      "Train Epoch: 3 [47872/54000 (89%)] Loss: 0.231198\n",
      "Train Epoch: 3 [49280/54000 (91%)] Loss: 0.272413\n",
      "Train Epoch: 3 [50688/54000 (94%)] Loss: 0.173238\n",
      "Train Epoch: 3 [52096/54000 (96%)] Loss: 0.307460\n",
      "Train Epoch: 3 [53504/54000 (99%)] Loss: 0.205913\n",
      "    val_my_metric2 : 0.9979815729483283\n",
      "    my_metric2     : 0.9883896834800271\n",
      "    my_metric      : 0.9284074559918755\n",
      "    val_loss       : 0.06867795469278985\n",
      "    val_my_metric  : 0.9770374240121581\n",
      "    loss           : 0.2432002895004094\n",
      "    epoch          : 3\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch3.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: 0.337488\n",
      "Train Epoch: 4 [1408/54000 (3%)] Loss: 0.208010\n",
      "Train Epoch: 4 [2816/54000 (5%)] Loss: 0.318924\n",
      "Train Epoch: 4 [4224/54000 (8%)] Loss: 0.252429\n",
      "Train Epoch: 4 [5632/54000 (10%)] Loss: 0.150255\n",
      "Train Epoch: 4 [7040/54000 (13%)] Loss: 0.182471\n",
      "Train Epoch: 4 [8448/54000 (16%)] Loss: 0.291611\n",
      "Train Epoch: 4 [9856/54000 (18%)] Loss: 0.181177\n",
      "Train Epoch: 4 [11264/54000 (21%)] Loss: 0.214448\n",
      "Train Epoch: 4 [12672/54000 (23%)] Loss: 0.186995\n",
      "Train Epoch: 4 [14080/54000 (26%)] Loss: 0.158086\n",
      "Train Epoch: 4 [15488/54000 (29%)] Loss: 0.121874\n",
      "Train Epoch: 4 [16896/54000 (31%)] Loss: 0.211181\n",
      "Train Epoch: 4 [18304/54000 (34%)] Loss: 0.169918\n",
      "Train Epoch: 4 [19712/54000 (36%)] Loss: 0.118481\n",
      "Train Epoch: 4 [21120/54000 (39%)] Loss: 0.232505\n",
      "Train Epoch: 4 [22528/54000 (42%)] Loss: 0.183967\n",
      "Train Epoch: 4 [23936/54000 (44%)] Loss: 0.146180\n",
      "Train Epoch: 4 [25344/54000 (47%)] Loss: 0.144871\n",
      "Train Epoch: 4 [26752/54000 (50%)] Loss: 0.238827\n",
      "Train Epoch: 4 [28160/54000 (52%)] Loss: 0.192316\n",
      "Train Epoch: 4 [29568/54000 (55%)] Loss: 0.233135\n",
      "Train Epoch: 4 [30976/54000 (57%)] Loss: 0.184345\n",
      "Train Epoch: 4 [32384/54000 (60%)] Loss: 0.244299\n",
      "Train Epoch: 4 [33792/54000 (63%)] Loss: 0.294902\n",
      "Train Epoch: 4 [35200/54000 (65%)] Loss: 0.172433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [36608/54000 (68%)] Loss: 0.227132\n",
      "Train Epoch: 4 [38016/54000 (70%)] Loss: 0.188084\n",
      "Train Epoch: 4 [39424/54000 (73%)] Loss: 0.106945\n",
      "Train Epoch: 4 [40832/54000 (76%)] Loss: 0.192848\n",
      "Train Epoch: 4 [42240/54000 (78%)] Loss: 0.276577\n",
      "Train Epoch: 4 [43648/54000 (81%)] Loss: 0.198926\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: 0.192840\n",
      "Train Epoch: 4 [46464/54000 (86%)] Loss: 0.231142\n",
      "Train Epoch: 4 [47872/54000 (89%)] Loss: 0.212083\n",
      "Train Epoch: 4 [49280/54000 (91%)] Loss: 0.253949\n",
      "Train Epoch: 4 [50688/54000 (94%)] Loss: 0.173965\n",
      "Train Epoch: 4 [52096/54000 (96%)] Loss: 0.353570\n",
      "Train Epoch: 4 [53504/54000 (99%)] Loss: 0.177755\n",
      "    val_my_metric2 : 0.9984802431610943\n",
      "    my_metric2     : 0.9902806575829384\n",
      "    my_metric      : 0.9366007955314828\n",
      "    val_loss       : 0.06459798743116095\n",
      "    val_my_metric  : 0.9800294452887538\n",
      "    loss           : 0.21580420568656017\n",
      "    epoch          : 4\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch4.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: 0.201751\n",
      "Train Epoch: 5 [1408/54000 (3%)] Loss: 0.159566\n",
      "Train Epoch: 5 [2816/54000 (5%)] Loss: 0.233522\n",
      "Train Epoch: 5 [4224/54000 (8%)] Loss: 0.318987\n",
      "Train Epoch: 5 [5632/54000 (10%)] Loss: 0.114619\n",
      "Train Epoch: 5 [7040/54000 (13%)] Loss: 0.180301\n",
      "Train Epoch: 5 [8448/54000 (16%)] Loss: 0.203962\n",
      "Train Epoch: 5 [9856/54000 (18%)] Loss: 0.110807\n",
      "Train Epoch: 5 [11264/54000 (21%)] Loss: 0.197637\n",
      "Train Epoch: 5 [12672/54000 (23%)] Loss: 0.098174\n",
      "Train Epoch: 5 [14080/54000 (26%)] Loss: 0.117735\n",
      "Train Epoch: 5 [15488/54000 (29%)] Loss: 0.256791\n",
      "Train Epoch: 5 [16896/54000 (31%)] Loss: 0.432831\n",
      "Train Epoch: 5 [18304/54000 (34%)] Loss: 0.192353\n",
      "Train Epoch: 5 [19712/54000 (36%)] Loss: 0.258770\n",
      "Train Epoch: 5 [21120/54000 (39%)] Loss: 0.159075\n",
      "Train Epoch: 5 [22528/54000 (42%)] Loss: 0.159616\n",
      "Train Epoch: 5 [23936/54000 (44%)] Loss: 0.366921\n",
      "Train Epoch: 5 [25344/54000 (47%)] Loss: 0.230465\n",
      "Train Epoch: 5 [26752/54000 (50%)] Loss: 0.089818\n",
      "Train Epoch: 5 [28160/54000 (52%)] Loss: 0.344945\n",
      "Train Epoch: 5 [29568/54000 (55%)] Loss: 0.252591\n",
      "Train Epoch: 5 [30976/54000 (57%)] Loss: 0.216023\n",
      "Train Epoch: 5 [32384/54000 (60%)] Loss: 0.174193\n",
      "Train Epoch: 5 [33792/54000 (63%)] Loss: 0.187697\n",
      "Train Epoch: 5 [35200/54000 (65%)] Loss: 0.233214\n",
      "Train Epoch: 5 [36608/54000 (68%)] Loss: 0.137335\n",
      "Train Epoch: 5 [38016/54000 (70%)] Loss: 0.326894\n",
      "Train Epoch: 5 [39424/54000 (73%)] Loss: 0.171748\n",
      "Train Epoch: 5 [40832/54000 (76%)] Loss: 0.203551\n",
      "Train Epoch: 5 [42240/54000 (78%)] Loss: 0.136867\n",
      "Train Epoch: 5 [43648/54000 (81%)] Loss: 0.130005\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: 0.182893\n",
      "Train Epoch: 5 [46464/54000 (86%)] Loss: 0.140583\n",
      "Train Epoch: 5 [47872/54000 (89%)] Loss: 0.213628\n",
      "Train Epoch: 5 [49280/54000 (91%)] Loss: 0.297973\n",
      "Train Epoch: 5 [50688/54000 (94%)] Loss: 0.122144\n",
      "Train Epoch: 5 [52096/54000 (96%)] Loss: 0.132327\n",
      "Train Epoch: 5 [53504/54000 (99%)] Loss: 0.331421\n",
      "    val_my_metric2 : 0.9988364361702128\n",
      "    my_metric2     : 0.9919626988828707\n",
      "    my_metric      : 0.9429481211916046\n",
      "    val_loss       : 0.057704254311132935\n",
      "    val_my_metric  : 0.9823565729483283\n",
      "    loss           : 0.19382652947546747\n",
      "    epoch          : 5\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch5.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: 0.137428\n",
      "Train Epoch: 6 [1408/54000 (3%)] Loss: 0.108082\n",
      "Train Epoch: 6 [2816/54000 (5%)] Loss: 0.128857\n",
      "Train Epoch: 6 [4224/54000 (8%)] Loss: 0.261460\n",
      "Train Epoch: 6 [5632/54000 (10%)] Loss: 0.241131\n",
      "Train Epoch: 6 [7040/54000 (13%)] Loss: 0.197616\n",
      "Train Epoch: 6 [8448/54000 (16%)] Loss: 0.136263\n",
      "Train Epoch: 6 [9856/54000 (18%)] Loss: 0.132987\n",
      "Train Epoch: 6 [11264/54000 (21%)] Loss: 0.159429\n",
      "Train Epoch: 6 [12672/54000 (23%)] Loss: 0.222880\n",
      "Train Epoch: 6 [14080/54000 (26%)] Loss: 0.260264\n",
      "Train Epoch: 6 [15488/54000 (29%)] Loss: 0.126048\n",
      "Train Epoch: 6 [16896/54000 (31%)] Loss: 0.188165\n",
      "Train Epoch: 6 [18304/54000 (34%)] Loss: 0.164341\n",
      "Train Epoch: 6 [19712/54000 (36%)] Loss: 0.154915\n",
      "Train Epoch: 6 [21120/54000 (39%)] Loss: 0.205073\n",
      "Train Epoch: 6 [22528/54000 (42%)] Loss: 0.225456\n",
      "Train Epoch: 6 [23936/54000 (44%)] Loss: 0.270612\n",
      "Train Epoch: 6 [25344/54000 (47%)] Loss: 0.191310\n",
      "Train Epoch: 6 [26752/54000 (50%)] Loss: 0.175957\n",
      "Train Epoch: 6 [28160/54000 (52%)] Loss: 0.138666\n",
      "Train Epoch: 6 [29568/54000 (55%)] Loss: 0.175514\n",
      "Train Epoch: 6 [30976/54000 (57%)] Loss: 0.136924\n",
      "Train Epoch: 6 [32384/54000 (60%)] Loss: 0.226830\n",
      "Train Epoch: 6 [33792/54000 (63%)] Loss: 0.216925\n",
      "Train Epoch: 6 [35200/54000 (65%)] Loss: 0.134946\n",
      "Train Epoch: 6 [36608/54000 (68%)] Loss: 0.219432\n",
      "Train Epoch: 6 [38016/54000 (70%)] Loss: 0.081741\n",
      "Train Epoch: 6 [39424/54000 (73%)] Loss: 0.245759\n",
      "Train Epoch: 6 [40832/54000 (76%)] Loss: 0.194914\n",
      "Train Epoch: 6 [42240/54000 (78%)] Loss: 0.220780\n",
      "Train Epoch: 6 [43648/54000 (81%)] Loss: 0.126639\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: 0.274421\n",
      "Train Epoch: 6 [46464/54000 (86%)] Loss: 0.139670\n",
      "Train Epoch: 6 [47872/54000 (89%)] Loss: 0.159473\n",
      "Train Epoch: 6 [49280/54000 (91%)] Loss: 0.160543\n",
      "Train Epoch: 6 [50688/54000 (94%)] Loss: 0.176509\n",
      "Train Epoch: 6 [52096/54000 (96%)] Loss: 0.310021\n",
      "Train Epoch: 6 [53504/54000 (99%)] Loss: 0.136316\n",
      "    val_my_metric2 : 0.9988126899696049\n",
      "    my_metric2     : 0.9921689869668247\n",
      "    my_metric      : 0.9470659487136086\n",
      "    val_loss       : 0.057044839763894996\n",
      "    val_my_metric  : 0.9826177811550152\n",
      "    loss           : 0.18486372084837954\n",
      "    epoch          : 6\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch6.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: 0.233090\n",
      "Train Epoch: 7 [1408/54000 (3%)] Loss: 0.123059\n",
      "Train Epoch: 7 [2816/54000 (5%)] Loss: 0.271131\n",
      "Train Epoch: 7 [4224/54000 (8%)] Loss: 0.154694\n",
      "Train Epoch: 7 [5632/54000 (10%)] Loss: 0.161915\n",
      "Train Epoch: 7 [7040/54000 (13%)] Loss: 0.131987\n",
      "Train Epoch: 7 [8448/54000 (16%)] Loss: 0.300708\n",
      "Train Epoch: 7 [9856/54000 (18%)] Loss: 0.318721\n",
      "Train Epoch: 7 [11264/54000 (21%)] Loss: 0.152427\n",
      "Train Epoch: 7 [12672/54000 (23%)] Loss: 0.111525\n",
      "Train Epoch: 7 [14080/54000 (26%)] Loss: 0.292685\n",
      "Train Epoch: 7 [15488/54000 (29%)] Loss: 0.163998\n",
      "Train Epoch: 7 [16896/54000 (31%)] Loss: 0.175307\n",
      "Train Epoch: 7 [18304/54000 (34%)] Loss: 0.093934\n",
      "Train Epoch: 7 [19712/54000 (36%)] Loss: 0.103555\n",
      "Train Epoch: 7 [21120/54000 (39%)] Loss: 0.106954\n",
      "Train Epoch: 7 [22528/54000 (42%)] Loss: 0.078947\n",
      "Train Epoch: 7 [23936/54000 (44%)] Loss: 0.209944\n",
      "Train Epoch: 7 [25344/54000 (47%)] Loss: 0.176843\n",
      "Train Epoch: 7 [26752/54000 (50%)] Loss: 0.167233\n",
      "Train Epoch: 7 [28160/54000 (52%)] Loss: 0.129774\n",
      "Train Epoch: 7 [29568/54000 (55%)] Loss: 0.093870\n",
      "Train Epoch: 7 [30976/54000 (57%)] Loss: 0.090329\n",
      "Train Epoch: 7 [32384/54000 (60%)] Loss: 0.096299\n",
      "Train Epoch: 7 [33792/54000 (63%)] Loss: 0.085112\n",
      "Train Epoch: 7 [35200/54000 (65%)] Loss: 0.201874\n",
      "Train Epoch: 7 [36608/54000 (68%)] Loss: 0.119457\n",
      "Train Epoch: 7 [38016/54000 (70%)] Loss: 0.221257\n",
      "Train Epoch: 7 [39424/54000 (73%)] Loss: 0.138816\n",
      "Train Epoch: 7 [40832/54000 (76%)] Loss: 0.097703\n",
      "Train Epoch: 7 [42240/54000 (78%)] Loss: 0.193257\n",
      "Train Epoch: 7 [43648/54000 (81%)] Loss: 0.181768\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: 0.323711\n",
      "Train Epoch: 7 [46464/54000 (86%)] Loss: 0.171145\n",
      "Train Epoch: 7 [47872/54000 (89%)] Loss: 0.245023\n",
      "Train Epoch: 7 [49280/54000 (91%)] Loss: 0.111603\n",
      "Train Epoch: 7 [50688/54000 (94%)] Loss: 0.055881\n",
      "Train Epoch: 7 [52096/54000 (96%)] Loss: 0.234693\n",
      "Train Epoch: 7 [53504/54000 (99%)] Loss: 0.186616\n",
      "    val_my_metric2 : 0.9993351063829787\n",
      "    my_metric2     : 0.9933353080568721\n",
      "    my_metric      : 0.9490785798916723\n",
      "    val_loss       : 0.047190249521047514\n",
      "    val_my_metric  : 0.9852298632218844\n",
      "    loss           : 0.17284301019569426\n",
      "    epoch          : 7\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch7.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: 0.105662\n",
      "Train Epoch: 8 [1408/54000 (3%)] Loss: 0.110077\n",
      "Train Epoch: 8 [2816/54000 (5%)] Loss: 0.212585\n",
      "Train Epoch: 8 [4224/54000 (8%)] Loss: 0.076672\n",
      "Train Epoch: 8 [5632/54000 (10%)] Loss: 0.298414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [7040/54000 (13%)] Loss: 0.187481\n",
      "Train Epoch: 8 [8448/54000 (16%)] Loss: 0.066302\n",
      "Train Epoch: 8 [9856/54000 (18%)] Loss: 0.198886\n",
      "Train Epoch: 8 [11264/54000 (21%)] Loss: 0.159810\n",
      "Train Epoch: 8 [12672/54000 (23%)] Loss: 0.144509\n",
      "Train Epoch: 8 [14080/54000 (26%)] Loss: 0.150703\n",
      "Train Epoch: 8 [15488/54000 (29%)] Loss: 0.224083\n",
      "Train Epoch: 8 [16896/54000 (31%)] Loss: 0.178481\n",
      "Train Epoch: 8 [18304/54000 (34%)] Loss: 0.200104\n",
      "Train Epoch: 8 [19712/54000 (36%)] Loss: 0.159400\n",
      "Train Epoch: 8 [21120/54000 (39%)] Loss: 0.134180\n",
      "Train Epoch: 8 [22528/54000 (42%)] Loss: 0.063308\n",
      "Train Epoch: 8 [23936/54000 (44%)] Loss: 0.113061\n",
      "Train Epoch: 8 [25344/54000 (47%)] Loss: 0.323972\n",
      "Train Epoch: 8 [26752/54000 (50%)] Loss: 0.211435\n",
      "Train Epoch: 8 [28160/54000 (52%)] Loss: 0.242715\n",
      "Train Epoch: 8 [29568/54000 (55%)] Loss: 0.223938\n",
      "Train Epoch: 8 [30976/54000 (57%)] Loss: 0.317470\n",
      "Train Epoch: 8 [32384/54000 (60%)] Loss: 0.147760\n",
      "Train Epoch: 8 [33792/54000 (63%)] Loss: 0.157816\n",
      "Train Epoch: 8 [35200/54000 (65%)] Loss: 0.161548\n",
      "Train Epoch: 8 [36608/54000 (68%)] Loss: 0.086123\n",
      "Train Epoch: 8 [38016/54000 (70%)] Loss: 0.141075\n",
      "Train Epoch: 8 [39424/54000 (73%)] Loss: 0.116207\n",
      "Train Epoch: 8 [40832/54000 (76%)] Loss: 0.280064\n",
      "Train Epoch: 8 [42240/54000 (78%)] Loss: 0.200358\n",
      "Train Epoch: 8 [43648/54000 (81%)] Loss: 0.070730\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: 0.112057\n",
      "Train Epoch: 8 [46464/54000 (86%)] Loss: 0.183511\n",
      "Train Epoch: 8 [47872/54000 (89%)] Loss: 0.216727\n",
      "Train Epoch: 8 [49280/54000 (91%)] Loss: 0.155596\n",
      "Train Epoch: 8 [50688/54000 (94%)] Loss: 0.141555\n",
      "Train Epoch: 8 [52096/54000 (96%)] Loss: 0.147688\n",
      "Train Epoch: 8 [53504/54000 (99%)] Loss: 0.126910\n",
      "    val_my_metric2 : 0.999501329787234\n",
      "    my_metric2     : 0.9937425947867299\n",
      "    my_metric      : 0.9519137186865267\n",
      "    val_loss       : 0.04801184985231846\n",
      "    val_my_metric  : 0.9856572948328267\n",
      "    loss           : 0.1615616429720727\n",
      "    epoch          : 8\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch8.pth ...\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: 0.107887\n",
      "Train Epoch: 9 [1408/54000 (3%)] Loss: 0.202409\n",
      "Train Epoch: 9 [2816/54000 (5%)] Loss: 0.138302\n",
      "Train Epoch: 9 [4224/54000 (8%)] Loss: 0.087073\n",
      "Train Epoch: 9 [5632/54000 (10%)] Loss: 0.127260\n",
      "Train Epoch: 9 [7040/54000 (13%)] Loss: 0.109771\n",
      "Train Epoch: 9 [8448/54000 (16%)] Loss: 0.149024\n",
      "Train Epoch: 9 [9856/54000 (18%)] Loss: 0.084594\n",
      "Train Epoch: 9 [11264/54000 (21%)] Loss: 0.105331\n",
      "Train Epoch: 9 [12672/54000 (23%)] Loss: 0.123591\n",
      "Train Epoch: 9 [14080/54000 (26%)] Loss: 0.170762\n",
      "Train Epoch: 9 [15488/54000 (29%)] Loss: 0.126412\n",
      "Train Epoch: 9 [16896/54000 (31%)] Loss: 0.081945\n",
      "Train Epoch: 9 [18304/54000 (34%)] Loss: 0.318540\n",
      "Train Epoch: 9 [19712/54000 (36%)] Loss: 0.070760\n",
      "Train Epoch: 9 [21120/54000 (39%)] Loss: 0.138474\n",
      "Train Epoch: 9 [22528/54000 (42%)] Loss: 0.183138\n",
      "Train Epoch: 9 [23936/54000 (44%)] Loss: 0.139504\n",
      "Train Epoch: 9 [25344/54000 (47%)] Loss: 0.161387\n",
      "Train Epoch: 9 [26752/54000 (50%)] Loss: 0.056395\n",
      "Train Epoch: 9 [28160/54000 (52%)] Loss: 0.127177\n",
      "Train Epoch: 9 [29568/54000 (55%)] Loss: 0.172393\n",
      "Train Epoch: 9 [30976/54000 (57%)] Loss: 0.141824\n",
      "Train Epoch: 9 [32384/54000 (60%)] Loss: 0.161322\n",
      "Train Epoch: 9 [33792/54000 (63%)] Loss: 0.165583\n",
      "Train Epoch: 9 [35200/54000 (65%)] Loss: 0.115896\n",
      "Train Epoch: 9 [36608/54000 (68%)] Loss: 0.104572\n",
      "Train Epoch: 9 [38016/54000 (70%)] Loss: 0.139503\n",
      "Train Epoch: 9 [39424/54000 (73%)] Loss: 0.294107\n",
      "Train Epoch: 9 [40832/54000 (76%)] Loss: 0.115286\n",
      "Train Epoch: 9 [42240/54000 (78%)] Loss: 0.054752\n",
      "Train Epoch: 9 [43648/54000 (81%)] Loss: 0.099475\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: 0.204179\n",
      "Train Epoch: 9 [46464/54000 (86%)] Loss: 0.170465\n",
      "Train Epoch: 9 [47872/54000 (89%)] Loss: 0.078858\n",
      "Train Epoch: 9 [49280/54000 (91%)] Loss: 0.159373\n",
      "Train Epoch: 9 [50688/54000 (94%)] Loss: 0.125565\n",
      "Train Epoch: 9 [52096/54000 (96%)] Loss: 0.087519\n",
      "Train Epoch: 9 [53504/54000 (99%)] Loss: 0.186278\n",
      "    val_my_metric2 : 0.9988364361702128\n",
      "    my_metric2     : 0.9940176455653352\n",
      "    my_metric      : 0.954063875253893\n",
      "    val_loss       : 0.04347636253434293\n",
      "    val_my_metric  : 0.986345934650456\n",
      "    loss           : 0.15712188612404876\n",
      "    epoch          : 9\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch9.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: 0.201967\n",
      "Train Epoch: 10 [1408/54000 (3%)] Loss: 0.211721\n",
      "Train Epoch: 10 [2816/54000 (5%)] Loss: 0.133889\n",
      "Train Epoch: 10 [4224/54000 (8%)] Loss: 0.163321\n",
      "Train Epoch: 10 [5632/54000 (10%)] Loss: 0.081407\n",
      "Train Epoch: 10 [7040/54000 (13%)] Loss: 0.213177\n",
      "Train Epoch: 10 [8448/54000 (16%)] Loss: 0.177785\n",
      "Train Epoch: 10 [9856/54000 (18%)] Loss: 0.212802\n",
      "Train Epoch: 10 [11264/54000 (21%)] Loss: 0.147121\n",
      "Train Epoch: 10 [12672/54000 (23%)] Loss: 0.132731\n",
      "Train Epoch: 10 [14080/54000 (26%)] Loss: 0.215670\n",
      "Train Epoch: 10 [15488/54000 (29%)] Loss: 0.123079\n",
      "Train Epoch: 10 [16896/54000 (31%)] Loss: 0.217246\n",
      "Train Epoch: 10 [18304/54000 (34%)] Loss: 0.089072\n",
      "Train Epoch: 10 [19712/54000 (36%)] Loss: 0.145473\n",
      "Train Epoch: 10 [21120/54000 (39%)] Loss: 0.103848\n",
      "Train Epoch: 10 [22528/54000 (42%)] Loss: 0.213667\n",
      "Train Epoch: 10 [23936/54000 (44%)] Loss: 0.078335\n",
      "Train Epoch: 10 [25344/54000 (47%)] Loss: 0.035457\n",
      "Train Epoch: 10 [26752/54000 (50%)] Loss: 0.253636\n",
      "Train Epoch: 10 [28160/54000 (52%)] Loss: 0.144763\n",
      "Train Epoch: 10 [29568/54000 (55%)] Loss: 0.080661\n",
      "Train Epoch: 10 [30976/54000 (57%)] Loss: 0.189237\n",
      "Train Epoch: 10 [32384/54000 (60%)] Loss: 0.120708\n",
      "Train Epoch: 10 [33792/54000 (63%)] Loss: 0.298894\n",
      "Train Epoch: 10 [35200/54000 (65%)] Loss: 0.172287\n",
      "Train Epoch: 10 [36608/54000 (68%)] Loss: 0.174424\n",
      "Train Epoch: 10 [38016/54000 (70%)] Loss: 0.152424\n",
      "Train Epoch: 10 [39424/54000 (73%)] Loss: 0.201441\n",
      "Train Epoch: 10 [40832/54000 (76%)] Loss: 0.098126\n",
      "Train Epoch: 10 [42240/54000 (78%)] Loss: 0.286659\n",
      "Train Epoch: 10 [43648/54000 (81%)] Loss: 0.200937\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: 0.140696\n",
      "Train Epoch: 10 [46464/54000 (86%)] Loss: 0.062866\n",
      "Train Epoch: 10 [47872/54000 (89%)] Loss: 0.173304\n",
      "Train Epoch: 10 [49280/54000 (91%)] Loss: 0.168089\n",
      "Train Epoch: 10 [50688/54000 (94%)] Loss: 0.101848\n",
      "Train Epoch: 10 [52096/54000 (96%)] Loss: 0.125250\n",
      "Train Epoch: 10 [53504/54000 (99%)] Loss: 0.097543\n",
      "    val_my_metric2 : 0.9990026595744681\n",
      "    my_metric2     : 0.993909212085308\n",
      "    my_metric      : 0.955002750507786\n",
      "    val_loss       : 0.04414382981176072\n",
      "    val_my_metric  : 0.9872007978723404\n",
      "    loss           : 0.1508809155939032\n",
      "    epoch          : 10\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch10.pth ...\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: 0.119332\n",
      "Train Epoch: 11 [1408/54000 (3%)] Loss: 0.157358\n",
      "Train Epoch: 11 [2816/54000 (5%)] Loss: 0.126859\n",
      "Train Epoch: 11 [4224/54000 (8%)] Loss: 0.161975\n",
      "Train Epoch: 11 [5632/54000 (10%)] Loss: 0.243953\n",
      "Train Epoch: 11 [7040/54000 (13%)] Loss: 0.100755\n",
      "Train Epoch: 11 [8448/54000 (16%)] Loss: 0.168785\n",
      "Train Epoch: 11 [9856/54000 (18%)] Loss: 0.123497\n",
      "Train Epoch: 11 [11264/54000 (21%)] Loss: 0.291012\n",
      "Train Epoch: 11 [12672/54000 (23%)] Loss: 0.076717\n",
      "Train Epoch: 11 [14080/54000 (26%)] Loss: 0.152336\n",
      "Train Epoch: 11 [15488/54000 (29%)] Loss: 0.066469\n",
      "Train Epoch: 11 [16896/54000 (31%)] Loss: 0.186715\n",
      "Train Epoch: 11 [18304/54000 (34%)] Loss: 0.166007\n",
      "Train Epoch: 11 [19712/54000 (36%)] Loss: 0.163556\n",
      "Train Epoch: 11 [21120/54000 (39%)] Loss: 0.250960\n",
      "Train Epoch: 11 [22528/54000 (42%)] Loss: 0.054839\n",
      "Train Epoch: 11 [23936/54000 (44%)] Loss: 0.159576\n",
      "Train Epoch: 11 [25344/54000 (47%)] Loss: 0.172359\n",
      "Train Epoch: 11 [26752/54000 (50%)] Loss: 0.203290\n",
      "Train Epoch: 11 [28160/54000 (52%)] Loss: 0.081355\n",
      "Train Epoch: 11 [29568/54000 (55%)] Loss: 0.185097\n",
      "Train Epoch: 11 [30976/54000 (57%)] Loss: 0.134201\n",
      "Train Epoch: 11 [32384/54000 (60%)] Loss: 0.133224\n",
      "Train Epoch: 11 [33792/54000 (63%)] Loss: 0.148934\n",
      "Train Epoch: 11 [35200/54000 (65%)] Loss: 0.111618\n",
      "Train Epoch: 11 [36608/54000 (68%)] Loss: 0.142213\n",
      "Train Epoch: 11 [38016/54000 (70%)] Loss: 0.113692\n",
      "Train Epoch: 11 [39424/54000 (73%)] Loss: 0.211848\n",
      "Train Epoch: 11 [40832/54000 (76%)] Loss: 0.045558\n",
      "Train Epoch: 11 [42240/54000 (78%)] Loss: 0.179321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [43648/54000 (81%)] Loss: 0.144551\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: 0.112160\n",
      "Train Epoch: 11 [46464/54000 (86%)] Loss: 0.100621\n",
      "Train Epoch: 11 [47872/54000 (89%)] Loss: 0.150950\n",
      "Train Epoch: 11 [49280/54000 (91%)] Loss: 0.101710\n",
      "Train Epoch: 11 [50688/54000 (94%)] Loss: 0.231430\n",
      "Train Epoch: 11 [52096/54000 (96%)] Loss: 0.195713\n",
      "Train Epoch: 11 [53504/54000 (99%)] Loss: 0.201939\n",
      "    val_my_metric2 : 0.9996675531914894\n",
      "    my_metric2     : 0.9943879062288423\n",
      "    my_metric      : 0.955521115436696\n",
      "    val_loss       : 0.04063850627379849\n",
      "    val_my_metric  : 0.987533244680851\n",
      "    loss           : 0.14877195366750962\n",
      "    epoch          : 11\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch11.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: 0.170723\n",
      "Train Epoch: 12 [1408/54000 (3%)] Loss: 0.097972\n",
      "Train Epoch: 12 [2816/54000 (5%)] Loss: 0.195444\n",
      "Train Epoch: 12 [4224/54000 (8%)] Loss: 0.102015\n",
      "Train Epoch: 12 [5632/54000 (10%)] Loss: 0.090808\n",
      "Train Epoch: 12 [7040/54000 (13%)] Loss: 0.104896\n",
      "Train Epoch: 12 [8448/54000 (16%)] Loss: 0.240578\n",
      "Train Epoch: 12 [9856/54000 (18%)] Loss: 0.108928\n",
      "Train Epoch: 12 [11264/54000 (21%)] Loss: 0.146858\n",
      "Train Epoch: 12 [12672/54000 (23%)] Loss: 0.103751\n",
      "Train Epoch: 12 [14080/54000 (26%)] Loss: 0.064289\n",
      "Train Epoch: 12 [15488/54000 (29%)] Loss: 0.109710\n",
      "Train Epoch: 12 [16896/54000 (31%)] Loss: 0.163741\n",
      "Train Epoch: 12 [18304/54000 (34%)] Loss: 0.079240\n",
      "Train Epoch: 12 [19712/54000 (36%)] Loss: 0.177160\n",
      "Train Epoch: 12 [21120/54000 (39%)] Loss: 0.115286\n",
      "Train Epoch: 12 [22528/54000 (42%)] Loss: 0.269854\n",
      "Train Epoch: 12 [23936/54000 (44%)] Loss: 0.168483\n",
      "Train Epoch: 12 [25344/54000 (47%)] Loss: 0.110790\n",
      "Train Epoch: 12 [26752/54000 (50%)] Loss: 0.148072\n",
      "Train Epoch: 12 [28160/54000 (52%)] Loss: 0.151939\n",
      "Train Epoch: 12 [29568/54000 (55%)] Loss: 0.098405\n",
      "Train Epoch: 12 [30976/54000 (57%)] Loss: 0.076222\n",
      "Train Epoch: 12 [32384/54000 (60%)] Loss: 0.162282\n",
      "Train Epoch: 12 [33792/54000 (63%)] Loss: 0.128966\n",
      "Train Epoch: 12 [35200/54000 (65%)] Loss: 0.095577\n",
      "Train Epoch: 12 [36608/54000 (68%)] Loss: 0.266559\n",
      "Train Epoch: 12 [38016/54000 (70%)] Loss: 0.126871\n",
      "Train Epoch: 12 [39424/54000 (73%)] Loss: 0.122562\n",
      "Train Epoch: 12 [40832/54000 (76%)] Loss: 0.327908\n",
      "Train Epoch: 12 [42240/54000 (78%)] Loss: 0.135031\n",
      "Train Epoch: 12 [43648/54000 (81%)] Loss: 0.150816\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: 0.159925\n",
      "Train Epoch: 12 [46464/54000 (86%)] Loss: 0.183300\n",
      "Train Epoch: 12 [47872/54000 (89%)] Loss: 0.240837\n",
      "Train Epoch: 12 [49280/54000 (91%)] Loss: 0.128430\n",
      "Train Epoch: 12 [50688/54000 (94%)] Loss: 0.150613\n",
      "Train Epoch: 12 [52096/54000 (96%)] Loss: 0.116815\n",
      "Train Epoch: 12 [53504/54000 (99%)] Loss: 0.079644\n",
      "    val_my_metric2 : 0.9991688829787234\n",
      "    my_metric2     : 0.9944460900473934\n",
      "    my_metric      : 0.9584117933310765\n",
      "    val_loss       : 0.04268542677164078\n",
      "    val_my_metric  : 0.9866546352583586\n",
      "    loss           : 0.1423836360636975\n",
      "    epoch          : 12\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch12.pth ...\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: 0.072160\n",
      "Train Epoch: 13 [1408/54000 (3%)] Loss: 0.116494\n",
      "Train Epoch: 13 [2816/54000 (5%)] Loss: 0.243180\n",
      "Train Epoch: 13 [4224/54000 (8%)] Loss: 0.110236\n",
      "Train Epoch: 13 [5632/54000 (10%)] Loss: 0.126825\n",
      "Train Epoch: 13 [7040/54000 (13%)] Loss: 0.160475\n",
      "Train Epoch: 13 [8448/54000 (16%)] Loss: 0.136197\n",
      "Train Epoch: 13 [9856/54000 (18%)] Loss: 0.135656\n",
      "Train Epoch: 13 [11264/54000 (21%)] Loss: 0.074155\n",
      "Train Epoch: 13 [12672/54000 (23%)] Loss: 0.120689\n",
      "Train Epoch: 13 [14080/54000 (26%)] Loss: 0.219507\n",
      "Train Epoch: 13 [15488/54000 (29%)] Loss: 0.146060\n",
      "Train Epoch: 13 [16896/54000 (31%)] Loss: 0.179456\n",
      "Train Epoch: 13 [18304/54000 (34%)] Loss: 0.163698\n",
      "Train Epoch: 13 [19712/54000 (36%)] Loss: 0.228578\n",
      "Train Epoch: 13 [21120/54000 (39%)] Loss: 0.177401\n",
      "Train Epoch: 13 [22528/54000 (42%)] Loss: 0.036796\n",
      "Train Epoch: 13 [23936/54000 (44%)] Loss: 0.172745\n",
      "Train Epoch: 13 [25344/54000 (47%)] Loss: 0.316650\n",
      "Train Epoch: 13 [26752/54000 (50%)] Loss: 0.157975\n",
      "Train Epoch: 13 [28160/54000 (52%)] Loss: 0.175871\n",
      "Train Epoch: 13 [29568/54000 (55%)] Loss: 0.193097\n",
      "Train Epoch: 13 [30976/54000 (57%)] Loss: 0.120605\n",
      "Train Epoch: 13 [32384/54000 (60%)] Loss: 0.053887\n",
      "Train Epoch: 13 [33792/54000 (63%)] Loss: 0.202499\n",
      "Train Epoch: 13 [35200/54000 (65%)] Loss: 0.187909\n",
      "Train Epoch: 13 [36608/54000 (68%)] Loss: 0.105425\n",
      "Train Epoch: 13 [38016/54000 (70%)] Loss: 0.100264\n",
      "Train Epoch: 13 [39424/54000 (73%)] Loss: 0.120600\n",
      "Train Epoch: 13 [40832/54000 (76%)] Loss: 0.084323\n",
      "Train Epoch: 13 [42240/54000 (78%)] Loss: 0.081517\n",
      "Train Epoch: 13 [43648/54000 (81%)] Loss: 0.024921\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: 0.061024\n",
      "Train Epoch: 13 [46464/54000 (86%)] Loss: 0.287416\n",
      "Train Epoch: 13 [47872/54000 (89%)] Loss: 0.187064\n",
      "Train Epoch: 13 [49280/54000 (91%)] Loss: 0.136175\n",
      "Train Epoch: 13 [50688/54000 (94%)] Loss: 0.142278\n",
      "Train Epoch: 13 [52096/54000 (96%)] Loss: 0.094300\n",
      "Train Epoch: 13 [53504/54000 (99%)] Loss: 0.102177\n",
      "    val_my_metric2 : 0.9988364361702128\n",
      "    my_metric2     : 0.9951125592417062\n",
      "    my_metric      : 0.9591258674678402\n",
      "    val_loss       : 0.0417737538747965\n",
      "    val_my_metric  : 0.9881743920972644\n",
      "    loss           : 0.13923810158913594\n",
      "    epoch          : 13\n",
      "Saving checkpoint: saved/Mnist_LeNet/0414_203632/checkpoint-epoch13.pth ...\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: 0.096916\n",
      "Train Epoch: 14 [1408/54000 (3%)] Loss: 0.088001\n",
      "Train Epoch: 14 [2816/54000 (5%)] Loss: 0.158790\n",
      "Train Epoch: 14 [4224/54000 (8%)] Loss: 0.088209\n",
      "Train Epoch: 14 [5632/54000 (10%)] Loss: 0.107867\n",
      "Train Epoch: 14 [7040/54000 (13%)] Loss: 0.138057\n",
      "Train Epoch: 14 [8448/54000 (16%)] Loss: 0.134808\n",
      "Train Epoch: 14 [9856/54000 (18%)] Loss: 0.260679\n",
      "Train Epoch: 14 [11264/54000 (21%)] Loss: 0.144519\n",
      "Train Epoch: 14 [12672/54000 (23%)] Loss: 0.090114\n",
      "Train Epoch: 14 [14080/54000 (26%)] Loss: 0.115665\n",
      "Train Epoch: 14 [15488/54000 (29%)] Loss: 0.169363\n",
      "Train Epoch: 14 [16896/54000 (31%)] Loss: 0.035982\n",
      "Train Epoch: 14 [18304/54000 (34%)] Loss: 0.105573\n",
      "Train Epoch: 14 [19712/54000 (36%)] Loss: 0.063448\n",
      "Train Epoch: 14 [21120/54000 (39%)] Loss: 0.097806\n",
      "Train Epoch: 14 [22528/54000 (42%)] Loss: 0.053661\n",
      "Train Epoch: 14 [23936/54000 (44%)] Loss: 0.099368\n",
      "Train Epoch: 14 [25344/54000 (47%)] Loss: 0.143765\n",
      "Train Epoch: 14 [26752/54000 (50%)] Loss: 0.218379\n",
      "Train Epoch: 14 [28160/54000 (52%)] Loss: 0.147658\n",
      "Train Epoch: 14 [29568/54000 (55%)] Loss: 0.111916\n",
      "Train Epoch: 14 [30976/54000 (57%)] Loss: 0.153499\n",
      "Train Epoch: 14 [32384/54000 (60%)] Loss: 0.093189\n",
      "Train Epoch: 14 [33792/54000 (63%)] Loss: 0.126465\n",
      "Train Epoch: 14 [35200/54000 (65%)] Loss: 0.133030\n",
      "Train Epoch: 14 [36608/54000 (68%)] Loss: 0.168367\n",
      "Train Epoch: 14 [38016/54000 (70%)] Loss: 0.130592\n",
      "Train Epoch: 14 [39424/54000 (73%)] Loss: 0.233836\n",
      "Train Epoch: 14 [40832/54000 (76%)] Loss: 0.130164\n",
      "Train Epoch: 14 [42240/54000 (78%)] Loss: 0.153419\n",
      "Train Epoch: 14 [43648/54000 (81%)] Loss: 0.097301\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: 0.118432\n",
      "Train Epoch: 14 [46464/54000 (86%)] Loss: 0.114031\n",
      "Train Epoch: 14 [47872/54000 (89%)] Loss: 0.123967\n",
      "Train Epoch: 14 [49280/54000 (91%)] Loss: 0.130304\n",
      "Train Epoch: 14 [50688/54000 (94%)] Loss: 0.042935\n",
      "Train Epoch: 14 [52096/54000 (96%)] Loss: 0.110665\n",
      "Train Epoch: 14 [53504/54000 (99%)] Loss: 0.262409\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f5cf6c1f3297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-297f8fd78711>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config, resume)\u001b[0m\n\u001b[1;32m     31\u001b[0m                       train_logger=train_logger)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KPMP/MNIST/pytorch-template/base/base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \"\"\"\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# save logged informations into log dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KPMP/MNIST/pytorch-template/trainer/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mval_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mval_log\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KPMP/MNIST/pytorch-template/trainer/trainer.py\u001b[0m in \u001b[0;36m_valid_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtotal_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mtotal_val_metrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# add histogram of model parameters to the tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KPMP/MNIST/pytorch-template/utils/visualization.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(tag, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_mode_exceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0madd_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.5/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_image\u001b[0;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         self.file_writer.add_summary(\n\u001b[0;32m--> 427\u001b[0;31m             image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.5/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.5/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(tensor, rescale, rois)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0mimage_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     ImageFile._save(im, _idat(fp, chunk),\n\u001b[0;32m--> 868\u001b[0;31m                     [(\"zip\", (0, 0)+im.size, 0, rawmode)])\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the network\n",
    "main(config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(config, resume):\n",
    "    # setup data_loader instances\n",
    "    data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "        config['data_loader']['args']['data_dir'],\n",
    "        batch_size=512,\n",
    "        shuffle=False,\n",
    "        validation_split=0.0,\n",
    "        training=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    # build model architecture\n",
    "    model = get_instance(module_arch, 'arch', config)\n",
    "    print(model)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "    \n",
    "    # get function handles of loss and metrics\n",
    "    loss_fn = getattr(module_loss, config['loss'])\n",
    "    metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "    \n",
    "    # load state dict\n",
    "    checkpoint = torch.load(resume)\n",
    "    state_dict = checkpoint['state_dict'] #dictionary of model parameters from saved file\n",
    "    if config['n_gpu'] > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict) \n",
    "    \n",
    "    # prepare model for testing\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval() #tells model to ignore dropout and batch normalization\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_metrics = torch.zeros(len(metric_fns))\n",
    "    \n",
    "    with torch.no_grad(): #speed up calculations, unable to perform back propogation\n",
    "        for i, (data, target) in enumerate(tqdm(data_loader)): #tqdm is a progress bar\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #\n",
    "            # save sample images, or do something with output here\n",
    "            #\n",
    "            \n",
    "            \n",
    "            if i < 5:\n",
    "                fig = plt.figure()\n",
    "                output_cpu = output.to(torch.device(\"cpu\"))\n",
    "                plt.title(\"Prediction = \" + str(np.argmax(output_cpu[1], axis=0)))\n",
    "                data_cpu = data.to(torch.device(\"cpu\"))\n",
    "                plt.imshow(data_cpu[1].view([28,28]))\n",
    "                \n",
    "            # computing loss, metrics on test set\n",
    "            loss = loss_fn(output, target)\n",
    "            batch_size = data.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            for i, metric in enumerate(metric_fns):\n",
    "                total_metrics[i] += metric(output, target) * batch_size\n",
    "        \n",
    "        plt.show()\n",
    "                      \n",
    "    n_samples = len(data_loader.sampler)\n",
    "    print(\"num samples = \" + str(n_samples))\n",
    "    log = {'loss': total_loss / n_samples}\n",
    "    log.update({met.__name__: total_metrics[i].item() / n_samples for i, met in enumerate(metric_fns)})\n",
    "    print(log)\n",
    "    print(\"My_metric is accuracy, my_metric2 is top-3 accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "resume = \"saved/Mnist_LeNet/0414_203632/model_best.pth\"\n",
    "\n",
    "print(os.path.isdir(\"saved/Mnist_LeNet/0414_203632\"))\n",
    "print(os.path.exists(resume))\n",
    "\n",
    "#config = torch.load(\"saved/Mnist_LeNet/0414_203632/config.json\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Trainable parameters: 21840\n",
      "Tesla K80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:01<00:00, 18.09it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples = 10000\n",
      "{'my_metric': 0.9867, 'loss': 0.04054535250663757, 'my_metric2': 0.9995}\n",
      "My_metric is accuracy, my_metric2 is top-3 accuracy\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "main2(config, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
